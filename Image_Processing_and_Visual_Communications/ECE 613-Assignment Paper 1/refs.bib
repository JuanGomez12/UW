@InProceedings {C2,
  author = 	 "Jones, C.D. and Smith, A.B. and Roberts, E.F.",
  title =        "Article Title",
  booktitle =        "Proceedings Title",
  organization = "IEEE",
  year = 	 "2003",
  volume = 	 "II",
  pages = 	 "803-806"
}
% This file was created with Citavi 6.3.0.0

@proceedings{.22.03.201624.03.2016,
 year = {22.03.2016 - 24.03.2016},
 title = {2016 International Conference on Wireless Communications, Signal Processing and Networking (WiSPNET)},
 publisher = {IEEE},
 isbn = {978-1-4673-9338-6}
}


@article{Wang.2016,
 abstract = {Archives of Computational Methods in Engineering, doi:10.1007/s11831-015-9154-z},
 author = {Wang, Zhaobin and Wang, Shuai and Zhu, Ying and Ma, Yide},
 year = {2016},
 title = {Review of Image Fusion Based on Pulse-Coupled Neural Network},
 pages = {659--671},
 volume = {23},
 number = {4},
 issn = {1134-3060},
 journal = {Archives of Computational Methods in Engineering},
 doi = {10.1007/s11831-015-9154-z}
}


@article{V.Bhateja.2015,
 author = {{V. Bhateja} and {H. Patel} and {A. Krishn} and {A. Sahu} and {A. Lay-Ekuakille}},
 year = {2015},
 title = {Multimodal Medical Image Sensor Fusion Framework Using Cascade of Wavelet and Contourlet Transform Domains},
 keywords = {Biomedical imaging;biomedical transducers;clinical analysis;computed tomography scanning;CT-Scan;image enhancement;Image fusion;image sensors;input image acquisition;magnetic resonance imaging;Measurement;medical image processing;MRI;multimodal medical image sensor fusion framework;Multi-modal Sensor Fusion;nonsubsampled Contourlet transform domain;NSCT;NSCT domain;PCA;principal component analysis;principal component analysis algorithm;Sensors;stationary wavelet transform;SWT;SWT domain;two-stage multimodal fusion framework;wavelet transform domain;wavelet transforms},
 pages = {6783--6790},
 volume = {15},
 number = {12},
 journal = {IEEE Sensors Journal},
 doi = {10.1109/JSEN.2015.2465935}
}


@inproceedings{V.22.03.201624.03.2016,
 abstract = {2016 International Conference on Wireless Communications, Signal Processing and Networking (WiSPNET);2016; ; ;10.1109/WiSPNET.2016.7566352},
 author = {V, Bhavana and K, Krishnappa H.},
 title = {A survey on multi - modality medical image fusion},
 pages = {1326--1329},
 publisher = {IEEE},
 isbn = {978-1-4673-9338-6},
 booktitle = {2016 International Conference on Wireless Communications, Signal Processing and Networking (WiSPNET)},
 year = {22.03.2016 - 24.03.2016},
 doi = {10.1109/WiSPNET.2016.7566352}
}


@article{Singh.2014,
 abstract = {Information Fusion, 19 (2014) 49-60. doi:10.1016/j.inffus.2012.09.005},
 author = {Singh, Rajiv and Khare, Ashish},
 year = {2014},
 title = {Fusion of multimodal medical images using Daubechies complex wavelet transform -- A multiresolution approach},
 keywords = {Daubechies complex wavelet transform;Fusion metrics;Medical imaging;Multimodal medical image fusion;Phase information;Wavelet transform},
 pages = {49--60},
 volume = {19},
 issn = {15662535},
 journal = {Information Fusion},
 doi = {10.1016/j.inffus.2012.09.005}
}


@article{Shen.2017,
 abstract = {This review covers computer-assisted analysis of images in the field of medical imaging. Recent advances in machine learning, especially with regard to deep learning, are helping to identify, classify, and quantify patterns in medical images. At the core of these advances is the ability to exploit hierarchical feature representations learned solely from data, instead of features designed by hand according to domain-specific knowledge. Deep learning is rapidly becoming the state of the art, leading to enhanced performance in various medical applications. We introduce the fundamentals of deep learning methods and review their successes in image registration, detection of anatomical and cellular structures, tissue segmentation, computer-aided disease diagnosis and prognosis, and so on. We conclude by discussing research issues and suggesting future directions for further improvement.},
 author = {Shen, Dinggang and Wu, Guorong and Suk, Heung-Il},
 year = {2017},
 title = {Deep Learning in Medical Image Analysis},
 keywords = {Algorithms;Diagnostic Imaging/methods;Image Enhancement/methods;Image Interpretation, Computer-Assisted/methods;Neural Networks (Computer);Pattern Recognition, Automated/methods;Unsupervised Machine Learning},
 pages = {221--248},
 volume = {19},
 journal = {Annual review of biomedical engineering},
 doi = {10.1146/annurev-bioeng-071516-044442}
}


@article{Sanjay.2017,
 author = {Sanjay, Agarwal and Soundrapandiyan, Rajkumar and Karuppiah, Marimuthu and Ganapathy, Rajasekaran},
 year = {2017},
 title = {CT and MRI Image Fusion Based on Discrete Wavelet Transform and Type-2 Fuzzy Logic},
 pages = {355--362},
 volume = {10},
 number = {3},
 journal = {International Journal of Intelligent Engineering and Systems},
 doi = {10.22266/ijies2017.0630.40}
}


@article{Rana.,
 abstract = {Comparative Analysis of Medical Image Fusion},
 author = {Rana, Aditi},
 title = {Comparative Analysis of Medical Image Fusion}
}


@article{Meher.2019,
 abstract = {Information Fusion, 48 (2019) 119-132. doi:10.1016/j.inffus.2018.07.010},
 author = {Meher, Bikash and Agrawal, Sanjay and Panda, Rutuparna and Abraham, Ajith},
 year = {2019},
 title = {A survey on region based image fusion methods},
 keywords = {Image fusion;Region based fusion;Segmentation},
 pages = {119--132},
 volume = {48},
 issn = {15662535},
 journal = {Information Fusion},
 doi = {10.1016/j.inffus.2018.07.010}
}


@article{Liu.2018,
 abstract = {Information Fusion, 42 (2018) 158-173. doi:10.1016/j.inffus.2017.10.007},
 author = {Liu, Yu and Chen, Xun and Wang, Zengfu and Wang, Z. Jane and Ward, Rabab K. and Wang, Xuesong},
 year = {2018},
 title = {Deep learning for pixel-level image fusion: Recent advances and future prospects},
 keywords = {Convolutional neural network;Convolutional sparse representation;Deep learning;Image fusion;Stacked autoencoder},
 pages = {158--173},
 volume = {42},
 issn = {15662535},
 journal = {Information Fusion},
 doi = {10.1016/j.inffus.2017.10.007}
}


@article{Yadav.2017,
 author = {Yadav, Jyotica and Dogra, Ayush and Goyal, Bhawna and Agrawal, Sunil},
 year = {2017},
 title = {A Review on Image Fusion Methodologies and Applications},
 pages = {1239},
 volume = {10},
 number = {4},
 issn = {0974-3618},
 journal = {Research Journal of Pharmacy and Technology},
 doi = {10.5958/0974-360X.2017.00221.9}
}


@article{Li.2017,
 abstract = {Information Fusion, 33 (2016) 100-112. doi:10.1016/j.inffus.2016.05.004},
 author = {Li, Shutao and Kang, Xudong and Fang, Leyuan and Hu, Jianwen and Yin, Haitao},
 year = {2017},
 title = {Pixel-level image fusion: A survey of the state of the art},
 keywords = {Image fusion;Medical imaging;Multiscale decomposition;remote sensing;Sparse representation},
 pages = {100--112},
 volume = {33},
 issn = {15662535},
 journal = {Information Fusion},
 doi = {10.1016/j.inffus.2016.05.004}
}

@article{Kaur.2015,
 abstract = {A Comparative Study of Various Digital Image Fusion Techniques: A Review},
 author = {Kaur, Prabhdeep and Kaur, Mandeep},
 year = {2015},
 title = {A Comparative Study of Various Digital Image Fusion Techniques: A Review},
 pages = {6--31},
 volume = {114},
 number = {4},
 journal = {International Journal of Computer Applications}
}





@misc{James.30.05.2015,
 abstract = {The fusion techniques that utilize multiple feature sets to form new features that are often more robust and contain useful information for future processing are referred to as feature fusion. The term data fusion is applied to the class of techniques used for combining decisions obtained from multiple feature sets to form global decisions. Feature and data fusion interchangeably represent two important classes of techniques that have proved to be of practical importance in a wide range of medical imaging problems},
 author = {James, Alex Pappachen and Dasarathy, Belur},
 date = {30.05.2015},
 title = {A Review of Feature and Data Fusion with Medical Images},
 url = {http://arxiv.org/pdf/1506.00097v1}
}


@article{DBLP:journals/corr/JamesD14,
  author    = {Alex Pappachen James and
               Belur V. Dasarathy},
  title     = {Medical Image Fusion: {A} survey of the state of the art},
  journal   = {CoRR},
  volume    = {abs/1401.0166},
  year      = {2014},
  url       = {http://arxiv.org/abs/1401.0166},
  archivePrefix = {arXiv},
  eprint    = {1401.0166},
  timestamp = {Mon, 13 Aug 2018 16:48:44 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/JamesD14},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@article{Jagalingam.2015,
 abstract = {Aquatic Procedia, 4 (2015) 133-142. doi:10.1016/j.aqpro.2015.02.019},
 author = {Jagalingam, P. and Hegde, Arkal Vittal},
 year = {2015},
 title = {A Review of Quality Metrics for Fused Image},
 keywords = {Image fusion;Qualitative.;Quantitative;remote sensing},
 pages = {133--142},
 volume = {4},
 issn = {2214-241X},
 journal = {Aquatic Procedia},
 doi = {10.1016/j.aqpro.2015.02.019}
}


@article{Ghassemian.2016,
 abstract = {Information Fusion, 32 (2016) 75-89. doi:10.1016/j.inffus.2016.03.003},
 author = {Ghassemian, Hassan},
 year = {2016},
 title = {A review of remote sensing image fusion methods},
 keywords = {high resolution image;Image fusion;remote sensing;survey},
 pages = {75--89},
 volume = {32},
 issn = {15662535},
 journal = {Information Fusion},
 doi = {10.1016/j.inffus.2016.03.003}
}


@article{Du.2016,
 abstract = {Neurocomputing, 215 + (2016) 3-20. doi:10.1016/j.neucom.2015.07.160},
 author = {Du, Jiao and Li, Weisheng and Lu, Ke and Xiao, Bin},
 year = {2016},
 title = {An overview of multi-modal medical image fusion},
 keywords = {Image decomposition;Image fusion;Image fusion rules;Image quality assessment;Image reconstruction;Multi-modal},
 pages = {3--20},
 volume = {215},
 issn = {0925-2312},
 journal = {Neurocomputing},
 doi = {10.1016/j.neucom.2015.07.160}
}


@inproceedings{BhavanaV..2016,
 year = {2016},
 title = {A survey on mulmodality medical image fusion:},
 booktitle = {2016 International Conference on Wireless Communications, Signal Processing and Networking (WiSPNET)},
 keywords = {brain disease;brain medical imaging;clinical diagnosis;computed tomography;CT;Image fusion;magnetic resonance imaging;Medical diagnostic imaging;medical image processing;modal analysis;MRI imaging;Multi - modal medical images;multimodality medical image fusion;PET imaging;positron emission tomography;Transforms},
 author = {{Bhavana V.} and {Krishnappa H.K.}},
 doi = {10.1109/WiSPNET.2016.7566352}
}


@article{Bhateja.2015,
 abstract = {IEEE Sensors Journal;2015;15;12;10.1109/JSEN.2015.2465935},
 author = {Bhateja, Vikrant and Patel, Himanshi and Krishn, Abhinav and Sahu, Akanksha and Lay-Ekuakille, Aime},
 year = {2015},
 title = {Multimodal Medical Image Sensor Fusion Framework Using Cascade of Wavelet and Contourlet Transform Domains},
 pages = {6783--6790},
 volume = {15},
 number = {12},
 issn = {1530-437X},
 journal = {IEEE Sensors Journal},
 doi = {10.1109/JSEN.2015.2465935}
}


@article{Agarwal.2015,
 abstract = {Image fusion is used to enhance the quality of images by combining two images of same scene obtained from different techniques. In medical diagnosis by combining the images obtained by Computed Tomography (CT) scan and Magnetic Resonance Imaging (MRI) we get more information and additional data from fused image. This paper presents a hybrid technique using curvelet and wavelet transform used in medical diagnosis. In this technique the image is segmented into bands using wavelet transform, the segmented image is then fused into sub bands using curvelet transform which breaks the bands into overlapping tiles and efficiently converting the curves in images using straight lines. These tiles are integrated together using inverse wavelet transform to produce a highly informative fused image. Wavelet based fusion extracts spatial details from high resolution bands but its limitation lies in the fusion of curved shapes. Therefore for better information and higher resolution on curved shapes we are blending wavelet transform with curvelet transform as we know that curvelet transform deals effectively with curves areas, corners and profiles. These two fusion techniques are extracted and then fused implementing hybrid image fusion algorithm, findings shows that fused image has minimum errors and present better quality results. The peak signal to noise ratio value for the hybrid method was higher in comparison to that of wavelet and curvelet transform fused images. Also we get improved statistics results in terms of Entropy, Peak signal to noise ratio, correlation coefficient, mutual information and edge association. This shows that the quality of fused image was better in case of hybrid method.},
 author = {Agarwal, Jyoti and Bedi, Sarabjeet Singh},
 year = {2015},
 title = {Implementation of hybrid image fusion technique for feature enhancement in medical diagnosis},
 url = {https://hcis-journal.springeropen.com/track/pdf/10.1186/s13673-014-0020-z},
 pages = {1--17},
 volume = {5},
 number = {1},
 issn = {2192-1962},
 journal = {Human-centric Computing and Information Sciences},
 doi = {10.1186/s13673-014-0020-z}
}


@article{Kayacan.2014,
 abstract = {Mechatronics, 24 (2014) 926-933. doi:10.1016/j.mechatronics.2014.03.007},
 author = {Kayacan, Erkan and Kayacan, Erdal and Ramon, Herman and Saeys, Wouter},
 year = {2014},
 title = {Distributed nonlinear model predictive control of an autonomous tractor--trailer system},
 pages = {926--933},
 volume = {24},
 number = {8},
 issn = {09574158},
 journal = {Mechatronics},
 doi = {10.1016/j.mechatronics.2014.03.007}
}


@article{Zafeiridis.2016,
 author = {Zafeiridis, P. and Papamarkos, N. and Goumas, S. and Seimenis, I.},
 year = {2016},
 title = {A New Sharpening Technique for Medical Images using Wavelets and Image Fusion},
 pages = {187--200},
 volume = {2016},
 number = {3},
 issn = {17919320},
 journal = {Journal of Engineering Science and Technology Review},
 doi = {10.25103/jestr.093.27}
}

@article{Bhateja.2015.1,
 author = {Bhateja, Vikrant and Krishn, Abhinav and Patel, Himanshi and Sahu, Akanksha},
 year = {2015},
 title = {Medical Image Fusion in Wavelet and Ridgelet Domains},
 pages = {78--91},
 volume = {2},
 number = {2},
 issn = {2334-4598},
 journal = {International Journal of Rough Sets and Data Analysis},
 doi = {10.4018/IJRSDA.2015070105}
}


@article{Deshmukh.2015,
 abstract = {International Journal of Scientific {\&} Engineering Research Volume 5, Issue 11, November-2015},
 author = {Deshmukh, Devyani P. and Malviya, A. V.},
 year = {2015},
 title = {Image Fusion an Application of Digital Image Processing using Wavelet Transform},
 keywords = {Entropy;Image fusion;Peak Signal to Noise Ratio;Root Mean Square Error;Spatial resolution;Spectral resolution.;Standard deviation;Wavelet transform},
 pages = {1247--1255},
 volume = {6},
 number = {11},
 journal = {International Journal of Scientific {\&} Engineering Research}
}

% This file was created with Citavi 6.3.0.0

@inproceedings{B.Deepa.2017,
 year = {2017},
 title = {{MRI} Medical Image Fusion Using Gradient Based Discrete Wavelet Transform},
 booktitle = {2017 IEEE International Conference on Computational Intelligence and Computing Research (ICCIC)},
 keywords = {average gradient;Biomedical imaging;biomedical MRI;brain;brain pathology;brain tumor;discrete wavelet transform;Discrete wavelet transforms;dual tree complex wavelet;DWT;Entropy;final fused image;FLAIR;FLAIR fusion result;fused image 1;fusion results;fusion symmetry;gradient measure;Image fusion;image fusion techniques;magnetic resonance imaging;medical diagnosis;medical image processing;medical images;MRI;MRI brain images;MRI images;MRI medical image fusion;PCA;principal component analysis;stroke;T1w;T2w;trees (mathematics);tumours;wavelet transforms},
 author = {{B. Deepa} and {M. G. Sumithra} and {T. D. Bharathi} and {S. Rajesh}},
 doi = {10.1109/ICCIC.2017.8524436}
}


@inproceedings{B.Rezaeifar.2017,
 abstract = {Nowadays, medical imaging becomes a common part of everyday clinical practices. Despite enormous progresses, still there is no single modality which can represent all aspects of the human body. For example, CT is suitable to view dense structures while MRI provides high resolution for soft tissue. In this paper, we propose a novel method for fusion of multimodal medical images. First, the surfacelet transform is used to decompose the source images. Then, we effectively combine the low and high frequency coefficients. Finally, inverse transform would provide the fused image. Experimental results exhibited the superior solution quality of our approach in comparison to a number of well-known counterpart algorithms.},
 year = {2017},
 title = {A new algorithm for multimodal medical image fusion based on the surfacelet transform},
 booktitle = {2017 7th International Conference on Computer and Knowledge Engineering (ICCKE)},
 keywords = {Biomedical imaging;computed tomography;Discrete wavelet transforms;high frequency coefficients;Hybrid fiber coaxial cables;Image fusion;inverse transform;inverse transforms;low frequency coefficients;medical image processing;Medical imaging;Multimodal medical image fusion;multimodal medical images;surfacelet transform},
 author = {{B. Rezaeifar} and {M. Saadatmand-Tarzjan}},
 doi = {10.1109/ICCKE.2017.8167911}
}




@inproceedings{K.Rajarshi.2016,
 abstract = {In clinical applications fusion of images plays a crucial role for best diagnosis. Here computed tomography(CT) image provides best information on denser tissues like bones and magnetic resonance image(MRI) provides better information on soft tissues. The fusion of these images will give better information about the patient medical status. This paper aims to propose a novel algorithm to improve the quality and quantity of an image using DWT. Here DWT preserve more detail in source images and further improves the quality of fused image. The Proposed algorithm uses approximation and detailed layer fusion rules and the performance are comparing with the multi-level local extrema (MLE) method [1]. The analysis of the proposed method has been performed with several sets of medical images. The Performances of fused multi-model images can be computed using PSNR (peak signal to noise ratio), MI (mutual information) and SSIM (structural similarity index). By observing the results, it shows that the proposed method is efficient for fusion process.},
 year = {2016},
 title = {DWT based medical image fusion with maximum local extrema},
 booktitle = {2016 International Conference on Computer Communication and Informatics (ICCCI)},
 keywords = {approximation;approximation theory;biomedical MRI;computed tomography;computerised tomography;CT image;detailed layer fusion rules;discrete wavelet transform;Discrete wavelet transforms;DWT (Discrete Wavelet Transformation);DWT based medical image fusion;Image fusion;image quality;image quantity;magnetic resonance image;Maximum likelihood estimation;maximum local extrema;Medical diagnostic imaging;medical image processing;MI;MLE;MRI;multilevel local extrema;multi-modal medical images;mutual information;peak signal-to-noise ratio;PSNR;SSIM;structural similarity index},
 author = {{K. Rajarshi} and {C. Himabindu}},
 doi = {10.1109/ICCCI.2016.7479948}
}


@inproceedings{M.Haribabu.2017,
 abstract = {Image fusion has one of the applications in Digital image processing. Image fusion is applicable in different domains like Medical, Satellite, military, Multi focus etc. In this paper, the proposed work based on Discrete Wavelet Transform (DWT) and visibility. The first step of proposed work is apply one level DWT on Gray level MRI image {\&} color information of intensity component of PET image to get four coefficients (approximation, vertical, horizontal {\&} diagonal). Based on comparison visibility condition of 8*8 window size of both image coefficients to obtain new four coefficients. Finally, to obtain fused image after applying Inverse Discrete Wavelet Transform (IDWT). This proposed work gives good result {\&} also improve the resolution of the image for better visual perception with respect to PSNR, MSE, Cross correlation, Mean, Standard Deviation, Entropy values.},
 author = {{M. Haribabu} and {C. H. Bindu}},
 year = {2017},
 title = {Visibility based multi modal medical image fusion with {DWT}},
 booktitle = {2017 IEEE International Conference on Power, Control, Signals and Instrumentation Engineering (ICPCSI)},
 keywords = {Biomedical imaging;biomedical MRI;Color Images;Conferences;cross correlation;digital image processing;Discrete wavelet transforms;DWT;Entropy;entropy values;gray level MRI image;IDWT;image coding;image coefficients;image colour analysis;Image fusion;image resolution;Instruments;intensity component color information;inverse discrete wavelet transform;magnetic resonance imaging;mean;mean square error methods;Medical Image Fusion;medical image processing;MSE;PET image;PSNR;Standard deviation;Visibility;visibility based multimodal medical image fusion;visual perception},
 organization = {IEEE},
 doi = {10.1109/ICPCSI.2017.8391973}
}


@inproceedings{S.Polinati.2019,
 abstract = {Nowadays, Image fusion seems to be the most promising area in image processing. It plays a pivotal role in different applications, namely medical diagnosis, object detection and recognition, navigation, military, civilian surveillance, robotics, satellite imaging for remote sensing. The process of image fusion aims to integrate two or more images into a single image, which consists of more useful information when compared with each of the source images without introducing any artefacts. In this review paper, three aspects are considered: image fusion methods on spatial domain and transform domain methods, Image fusion rules on transform domain method and image fusion metrics. This review includes different applications, including medical image fusion methodologies.},
 year = {2019},
 title = {A Review on Multi-Model Medical Image Fusion},
 booktitle = {2019 International Conference on Communication and Signal Processing (ICCSP)},
 keywords = {Biomedical imaging;civilian surveillance;Distortion;Feature extraction;Fusion Rules;Image fusion;image fusion methods;Image fusion rules;image processing;magnetic resonance imaging;Measurement;medical diagnosis;medical image fusion methodologies;medical image processing;Metrics;military surveillance;multimodel medical Image fusion;navigation;object detection;object recognition;remote sensing;robotics;satellite imaging;single image;source images;Spatial Domain;Transform Domain;Transforms},
 author = {{S. Polinati} and {R. Dhuli}},
 doi = {10.1109/ICCSP.2019.8697906}
}


@inproceedings{V.Bhavana.2016,
 abstract = {Image fusion technique integrates suitable information from various modalities of input images into a fused distinct image where the resultant image provides better information in comparison with the input images which are used for fusion and is more appropriate for visual perception. This work presents an image fusion method which performs wavelet decomposition for both PET and MRI images with different activity levels. This method generates promising fusion results by varying the structural information in the gray matter area and the spectral information in the white matter area to have better color preservation. Moreover, to produce good spectral resolution, smoothing filters is applied to the low frequency region and adaptive histogram equalization is performed to obtain a high contrast fused output image.},
 year = {2016},
 title = {Fusion of MRI and PET images using DWT and adaptive histogram equalization},
 booktitle = {2016 International Conference on Communication and Signal Processing (ICCSP)},
 keywords = {activity levels;adaptive histogram equalization;biomedical MRI;color preservation;discrete wavelet transform;Discrete wavelet transforms;diseases;DWT;Graphical user interfaces;gray matter area;high contrast fused output image;Image color analysis;image colour analysis;image filtering;Image fusion;image resolution;low frequency region;magnetic resonance imaging;medical image processing;medical images;MRI;MRI image fusion;PET;PET image fusion;positron emission tomography;smoothing filters;spectral information;spectral resolution;structural information;Transforms;visual perception;white matter area},
 author = {{V. Bhavana} and {H. K. Krishnappa}},
 doi = {10.1109/ICCSP.2016.7754254}
}


@inproceedings{Y.Liu.2018,
 abstract = {Medical image fusion offers an important approach by integrating complimentary features of different imaging modalities to acquire a high-quality image. For the fusion of medical images that it is very helpful to medical exploration and clinical diagnosis. An image fusion method for CT and MRI medical image using nonsubsampled shearlet transform (NSST) and dictionary learning which is based on sparse representation (SR) theory is presented. NSST and dictionary learning are two most extensively used image representation theories. Firstly, the source image is decomposed by NSST to get low frequency coefficients and the high frequency coefficients. Secondly, the high frequency coefficients are merged using the absolute-maximum rule while the low frequency coefficients are fused with a SR-based fusion approach. Finally, the fused image is obtained by inverse NSST. The results show that the proposed method achieves the best performance in both subjective and objective evaluation.},
 year = {2018},
 title = {Brain CT and MRI medical image fusion scheme Using NSST And Dictionary Learning},
 booktitle = {2018 IEEE 4th International Conference on Computer and Communications (ICCC)},
 keywords = {absolute-maximum rule;biomedical MRI;brain;brain CT medical image fusion;brain MRI medical image fusion;clinical diagnosis;computed tomography;computerised tomography;dictionary learning;dictionary learning theory;Discrete wavelet transforms;frequency coefficients;high-quality image;Image fusion;image representation;image representation theories;inverse NSST;magnetic resonance imaging;Medical diagnostic imaging;medical exploration;medical image processing;medical images;nonsubsampled shearlet transform;NSST;Sparse representation;sparse representation theory;SR-based fusion approach;Transforms},
 author = {{Y. Liu} and {D. Zhou} and {R. Nie} and {R. Hou} and {Z. Ding} and {R. Xie}},
 organization = {IEEE},
 doi = {10.1109/CompComm.2018.8780625}
}


%%% DWT

@article{Pajares.Delacruz.2004,
 author   = {{Gonzalo Pajares} and {Jes√∫s Manuel de la Cruz}},
 year     = {2004},
 title    = {A wavelet-based image fusion tutorial},
 keywords = {Image fusion; Wavelets; Multiresolution},
 pages    = {1855--1872},
 journal  = {The Journal of Pattern Recognition Society}
}

@Book{Gonzalez.Woods.2008,
 author    = {{Rafael C. Gonzalez} and {Richard E. Woods}},
 title     = {Digital Image Processing},
 publisher = {Pearson Prentice Hall},
 year      =  {2008},
 address   = {Upper Saddle River, NJ},
 edition   = "Third"
}

@Book{Gonzalez.Woods.Eddins.2009,
 author    = {{Rafael C. Gonzalez} and {Richard E. Woods} and {Steven L. Eddins}},
 title     = {Digital Image Processing using MATLAB},
 publisher = {Gatesmark},
 year      =  {2009},
 edition   = "Second",
 isbn      = {978-0-9820854-0-0}
}

@article{Mallat.1989,
 author   = {{Stephane Mallat}},
 year     = {1989},
 title    = {A Theory for Multiresolution Signal Decomposition: The Wavelet Representation},
 volume   = 11,
 issue    = 7,
 keywords = {Coding, Fractals, multiresolution pyramids, quadrature mirror filters, texture discrimination, wavelet transform},
 pages    = {674--693},
 journal  = {IEEE Transactions on Pattern Analysis and Machine Intelligence}
 }
 
@article{Sahu.Parsai.2012,
 author   = {{Deepak Kumar Sahu} and {M. P. Parsai}},
 year     = {2012},
 title    = {Different Image Fusion Techniques - A Critical Review},
 volume   = 2,
 issue    = 5,
 keywords = {Discrete Wavelet Transform (DWT), Mean Square Error (MSE), Normalized correlation (NC), Peak signal to noise ratio (PSNR), Principal Component Analysis (PCA)},
 pages    = {4298--4301},
 journal  = {International Journal of Modern Engineering Research (IJMER)}
 }
 
 @inproceedings{Chiorean.Vaida.2009,
 author   = {{Ligia Chiorean} and {Mircea - Florin Vaida}},
 year     = {2009},
 title    = {Medical Image Fusion Based on Discrete Wavelet Transform Using Java Technology},
 booktitle = {Proceedings of the ITI 2009 31st Int. Conf. on Information Technology Interfaces},
 pages    = {55--60},
 organization  = {IEEE},
 isbn = {978-953-7138-15-8}
 }
 
 
 @article{Kavitha.Chellamuthu.Rajesh.2012,
 author   = {{C.T. Kavitha} and {C. Chellamuthu} and {R. Rajesh}},
 year     = {2012},
 title    = {Medical Image Fusion Using Combined Discrete Wavelet and Ripplet Transforms},
 volume   = 38,
 pages    = {813--820},
 journal  = {Journal of Procedia Engineering}
}

 @inproceedings{Cheng.He.Lv.2008,
 author   = {{Shangli Cheng} and {Junmin He} and {Zhongwei Lv}},
 year     = {2008},
 title    = {Medical Image of {PET/CT} Weighted Fusion Based on Wavelet Transform},
 booktitle = {2008 2nd International Conference on Bioinformatics and Biomedical Engineering},
 pages    = {55--60},
 organization  = {IEEE},
 isbn = {978-1-4244-1747-6}
 }

%%% DWT End

%%% Bib Dual Tree 

@article{IvanW.Selesnick.2005,
 author = {{Ivan W. Selesnick} and {Richard G. Baraniuk} and {Nick G. Kingsbury}},
 year = {2005},
 title = {The Dual-Tree Complex Wavelet Transform: A coherent framework for multiscale signal and image processing},
 keywords = {Keywords},
 pages = {123--151},
 journal = {IEEE SIGNAL PROCESSING MAGAZINE},
 file = {d6a36f66-fd17-4b83-a9de-558dcf65fc7f:C\:\\Users\\mirco\\AppData\\Local\\Swiss Academic Software\\Citavi 6\\ProjectCache\\wlc6nphpv7nw7rectrwrrib4r0t54kcwb8qwj2b7uym4qgkx\\Citavi Attachments\\d6a36f66-fd17-4b83-a9de-558dcf65fc7f.pdf:pdf}
}

@proceedings{K.Padmavathi.2016,
 abstract = {Combining various modalities of medical images increases robustness and improve accuracy in medical research and diagnosis of diseases. A significant task for retrieving complementary information from different modality of medical images such as MRI, CT, PET and SPECT can be achieved by multimodal medical image fusion. Different characteristics of low and high frequency sub bands are taken into account and fusion rules are applied. In the proposed method, DTCWT (Dual Tree Complex Wavelet Transform) is applied to extract salient information from each modality. Fusion rule is applied with PCA features. Performance analysis is carried out between the proposed fusion method and other existing methods. Improvement in visual quality can be seen in the proposed method.},
 year = {2016},
 title = {Medical image fusion of different modalities using dual tree complex wavelet transform with PCA: 2016 International Conference on Circuits, Controls, Communications and Computing (I4C)},
 keywords = {biomedical MRI;complementary information;decomposition;Discrete wavelet transforms;diseases;DTCWT;dual tree complex wavelet transform;DWT;Feature extraction;fusion method;fusion rule;Fusion Rules;high frequency sub bands;Image fusion;image modality;low frequency sub bands;Medical diagnostic imaging;medical image processing;medical images;medical research;Multimodal medical image fusion;PCA;PCA features;principal component analysis;trees (mathematics);visual quality;wavelet transforms},
 editor = {{K. Padmavathi} and {M. V. Karki} and {M. Bhat}},
 doi = {10.1109/CIMCA.2016.8053288},
 file = {9dc50b11-5f33-49ed-952e-6c4175a43285:C\:\\Users\\mirco\\AppData\\Local\\Swiss Academic Software\\Citavi 6\\ProjectCache\\wlc6nphpv7nw7rectrwrrib4r0t54kcwb8qwj2b7uym4qgkx\\Citavi Attachments\\9dc50b11-5f33-49ed-952e-6c4175a43285.pdf:pdf}
}

@inproceedings{Talbi.2018,
 year = {2018},
 title = {Predator prey optimizer and DTCWT for multimodal medical image fusion},
 booktitle = {2018 International Symposium on Programming and Systems (ISPS)},
 keywords = {absolute maximum method;Discrete wavelet transforms;DTCWT;dual tree complex wavelet transform;Dual-Tree Complex Wavelet Transform;high-frequency coefficients;hybrid algorithm;Image fusion;image resolution;low-frequency coefficients;Medical diagnostic imaging;medical image processing;Multimodal medical image fusion;multimodal medical images;Multiresolution analysis;multiresolution transform;predator prey optimizer;predator-prey systems;trees (mathematics);wavelet transforms;weighted average method},
 author = {Talbi, H. and Kholladi, M. K.},
 doi = {10.1109/ISPS.2018.8379023},
 file = {0216fd75-d43f-457d-80e9-28d747370753:C\:\\Users\\mirco\\AppData\\Local\\Swiss Academic Software\\Citavi 6\\ProjectCache\\wlc6nphpv7nw7rectrwrrib4r0t54kcwb8qwj2b7uym4qgkx\\Citavi Attachments\\0216fd75-d43f-457d-80e9-28d747370753.pdf:pdf}
}

@inproceedings{Xiaozhu.27.07.201529.07.2015,
 abstract = {2015 34th Chinese Control Conference (CCC);2015; ; ;10.1109/ChiCC.2015.7260392},
 author = {Xiao-zhu, Xie and Ya-wei, Xu},
 title = {Multi-sensor image fusion scheme based on dual-tree complex wavelet transform},
 pages = {4857--4861},
 organization = {IEEE},
 isbn = {978-9-8815-6389-7},
 booktitle = {2015 34th Chinese Control Conference (CCC)},
 year = {2015},
 doi = {10.1109/ChiCC.2015.7260392},
 file = {61c29c7a-2791-4ad2-908b-c538409dd5bb:C\:\\Users\\mirco\\AppData\\Local\\Swiss Academic Software\\Citavi 6\\ProjectCache\\wlc6nphpv7nw7rectrwrrib4r0t54kcwb8qwj2b7uym4qgkx\\Citavi Attachments\\61c29c7a-2791-4ad2-908b-c538409dd5bb.pdf:pdf}
}

@article{Srivastava.2016,
 author = {Srivastava, Richa and Khare, Ashish},
 year = {2016},
 title = {Threshold based Image Fusion in Dual Tree Complex Wavelet Domain},
 pages = {64--74},
 number = {10},
 journal = {I.J. Image, Graphics and Signal Processing},
 doi = {10.5815/ijigsp.2016.10.08},
 file = {d9e3f32c-903f-4b2b-930b-f8507490256e:C\:\\Users\\mirco\\AppData\\Local\\Swiss Academic Software\\Citavi 6\\ProjectCache\\wlc6nphpv7nw7rectrwrrib4r0t54kcwb8qwj2b7uym4qgkx\\Citavi Attachments\\d9e3f32c-903f-4b2b-930b-f8507490256e.pdf:pdf}
}

@Article{Wang2004,
author="Wang, Hai-hui",
title="A New Multiwavelet-Based Approach to Image Fusion",
journal="Journal of Mathematical Imaging and Vision",
year="2004",
month="Sep",
day="01",
volume="21",
number="2",
pages="177--192",
abstract="Image fusion refers to the techniques that integrate complementary information from multiple image sensor data such that the new images are more suitable for the purpose of human visual perception and the compute-processing tasks. In this paper, a new image fusion algorithm based on multiwavelet transform to fuse multisensor images is presented. The detailed discussions in the paper are focused on the two-wavelet and two-scaling function multiwavelets. Multiwavelets are extensions from scalar wavelet, and have several unique advantages in comparison with scalar wavelets, so that multiwavelet is employed to decompose and reconstruct images in this algorithm. In this paper, the image fusion is performed at the pixel level, other types of image fusion schemes, such as feature or decision fusion, are not considered. In this fusion algorithm, a feature-based fusion rule is used to combine original subimages and to form a pyramid for the fused image. When images are merged in multiwavelet space, different frequency ranges are processed differently. It can merge information from original images adequately and improve abilities of information analysis and feature extraction. Extensive experiments including the fusion of registered multiband SPOT multispectral XS1{\backslash}XS3 images, multifocus digital camera images, multisensor of VIS{\backslash}IR images, and medical CT{\backslash}MRI images are presented in this paper. In this paper, mutual information is employed as a means of objective assessing image fusion performance. The experiment results show that this fusion algorithm, based on multiwavelet transform, is an effective approach in image fusion area.",
issn="1573-7683",
doi="10.1023/B:JMIV.0000035181.00093.e3",
url="https://doi.org/10.1023/B:JMIV.0000035181.00093.e3"
}

@INPROCEEDINGS{Liu2010, 
author={ {Yuhui Liu} and {Jinzhu Yang} and {Jinshan Sun}}, 
booktitle={2010 2nd International Conference on Advanced Computer Control}, 
title={PET/CT medical image fusion algorithm based on multiwavelet transform}, 
year={2010}, 
volume={2}, 
number={}, 
pages={264-268}, 
keywords={computerised tomography;image fusion;medical image processing;positron emission tomography;wavelet transforms;medical image fusion algorithm;PET-CT fusion;multiwavelet transform;wavelet coefficient fusion method;gradient fusion;classification fusion;Positron emission tomography;Computed tomography;Biomedical imaging;Image fusion;Medical diagnostic imaging;Wavelet transforms;Algorithm design and analysis;Wavelet domain;Biomedical engineering;Image processing;PET/CT;image fusion;multiwavelet transform}, 
doi={10.1109/ICACC.2010.5486674}, 
ISSN={}, 
month={March},}

@article{Peng2015,
author = {Peng, Geng and Su, Xing and Xu, Tan and Liu, Jianshu},
year = {2015},
month = {11},
pages = {75-84},
title = {Multi-modal Medical Image Fusion Based on the Multiwavelet and Nonsubsampled Direction Filter Bank},
volume = {8},
journal = {International Journal of Signal Processing, Image Processing and Pattern Recognition},
doi = {10.14257/ijsip.2015.8.11.08}
}

% This file was created with Citavi 6.3.0.0

@article{Singh.2015,
 author = {Singh, Rohit Raj and Mishra, Ravi},
 year = {2015},
 title = {Benefits of Dual Tree Complex Wavelet Transform over Discrete Wavelet Transform for Image Fusion},
 keywords = {Discrete Wavelet Transform (DWT);Dual-Tree Complex Wavelet Transform (DT-CWT);Image fusion;Keywords: Wavelet Transform},
 volume = {1},
 number = {11},
 journal = {IJIRST},
}


@inproceedings{Goel.2017,
 year = {2017},
 title = {{CT} and {MRI} Image Fusion using Wiener filter in Dual Tree Framework},
 booktitle = {2017 2nd International Conference on Telecommunication and Networks (TEL-NET)},
 author = {Goel, Shweta and Budhiraja, Sumit and Dhindsa, Anaahat and Metha, Nancy},
 organization = {IEEE},
}






%%% Bib End Dual Tree







